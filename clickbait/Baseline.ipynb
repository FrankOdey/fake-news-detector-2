{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset():\n",
    "    clickbait = []\n",
    "    non_clickbait = []\n",
    "    with open(\"data/clickbait_data\", 'rt') as data_in:\n",
    "        for line in data_in:\n",
    "            if line.strip():\n",
    "                clickbait.append(line.strip())\n",
    "                \n",
    "                \n",
    "    with open(\"data/non_clickbait_data\", 'rt') as data_in:\n",
    "        for line in data_in:\n",
    "            if line.strip():\n",
    "                non_clickbait.append(line.strip())\n",
    "\n",
    "    return clickbait, non_clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbait, non_clickbait = parse_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_titles(titles): \n",
    "    return list(map(lambda x: x.lower(), titles))\n",
    "    \n",
    "def create_dataframe(clickbait=clickbait, non_clickbait=non_clickbait):\n",
    "    cb_df = pd.DataFrame({'clickbait': np.ones(len(clickbait)), 'title': preprocess_titles(clickbait)})\n",
    "    n_cb_df = pd.DataFrame({'clickbait': np.zeros(len(non_clickbait)), 'title': preprocess_titles(non_clickbait)})\n",
    "    return pd.concat([cb_df, n_cb_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = create_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clickbait</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>should i get bings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>which tv female friend group do you belong in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the new \"star wars: the force awakens\" trailer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>this vine of new york on \"celebrity big brothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>a couple did a stunning photo shoot with their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>how to flirt with queer girls without making a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32 cute things to distract from your awkward t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>if disney princesses were from florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>what's a quote or lyric that best describes yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>natalie dormer and sam claflin play a game to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clickbait                                              title\n",
       "0        1.0                                 should i get bings\n",
       "1        1.0      which tv female friend group do you belong in\n",
       "2        1.0  the new \"star wars: the force awakens\" trailer...\n",
       "3        1.0  this vine of new york on \"celebrity big brothe...\n",
       "4        1.0  a couple did a stunning photo shoot with their...\n",
       "5        1.0  how to flirt with queer girls without making a...\n",
       "6        1.0  32 cute things to distract from your awkward t...\n",
       "7        1.0             if disney princesses were from florida\n",
       "8        1.0  what's a quote or lyric that best describes yo...\n",
       "9        1.0  natalie dormer and sam claflin play a game to ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_tokenizer = TfidfVectorizer(max_features=30000, stop_words='english').fit(titles['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titles['title'], titles['clickbait'],\n",
    "                                                    stratify=titles['clickbait'], \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "def show_scores(model, x, y):\n",
    "    cv_score = cross_val_score(model, x, y, cv=5, n_jobs=-1)\n",
    "    print('Cross val score', cv_score, cv_score.mean())\n",
    "    predict = cross_val_predict(model, x, y, cv=5, n_jobs=-1)\n",
    "    print(classification_report(y_pred =predict, y_true=y))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score [0.94771923 0.94458333 0.94895833 0.94395833 0.94748906] 0.9465416570764609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.97      0.95     12001\n",
      "        1.0       0.97      0.92      0.95     11999\n",
      "\n",
      "avg / total       0.95      0.95      0.95     24000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11679   322]\n",
      " [  961 11038]]\n"
     ]
    }
   ],
   "source": [
    "show_scores(LogisticRegression(), idf_tokenizer.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score [0.95667569 0.95       0.95604167 0.95375    0.95686601] 0.9546666745967162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.97      0.96     12001\n",
      "        1.0       0.97      0.94      0.95     11999\n",
      "\n",
      "avg / total       0.95      0.95      0.95     24000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11597   404]\n",
      " [  684 11315]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "show_scores(LinearSVC(), idf_tokenizer.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "\n",
    "train_tokenized = idf_tokenizer.transform(X_train)\n",
    "test_tokenized = idf_tokenizer.transform(X_test)\n",
    "\n",
    "svc.fit(train_tokenized, y_train)\n",
    "\n",
    "predict = svc.predict(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.96      4000\n",
      "        1.0       0.96      0.95      0.96      4000\n",
      "\n",
      "avg / total       0.96      0.96      0.96      8000\n",
      "\n",
      "[[3853  147]\n",
      " [ 202 3798]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=predict, y_true=y_test))\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
