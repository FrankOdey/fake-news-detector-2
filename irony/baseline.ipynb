{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from Utilities import preprocessing, plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sweet United Nations video. Just in time for Christmas. #imagine #NoReligion  http://t.co/fej2v3OUBR', \"@mrdahl87 We are rumored to have talked to Erv's agent... and the Angels asked about Ed Escobar... that's hardly nothing    ;)\", 'Hey there! Nice to see you Minnesota/ND Winter Weather', \"3 episodes left I'm dying over here\", '\"I can\\'t breathe!\" was chosen as the most notable quote of the year in an annual list released by a Yale University librarian']\n",
      "[1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "tweets, labels = preprocessing.parse_dataset('datasets/train/SemEval2018-T3-train-taskA.txt')\n",
    "print(tweets[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(model, x = tweets, y = labels):\n",
    "    print('Cross val score', cross_val_score(model, x, y, cv=3, n_jobs=2))\n",
    "    predict = cross_val_predict(model, x, y, cv=3, n_jobs=2)\n",
    "    print('Accuracy',accuracy_score(y, predict))\n",
    "    print('Precision',precision_score(y, predict))\n",
    "    print('Recall',recall_score(y, predict))\n",
    "    print('F1', f1_score(y, predict))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score [ 0.6713615   0.63849765  0.64084507]\n",
      "Accuracy 0.650234741784\n",
      "Precision 0.651757188498\n",
      "Recall 0.640502354788\n",
      "F1 0.646080760095\n",
      "Confusion Matrix:\n",
      "[[1269  654]\n",
      " [ 687 1224]]\n"
     ]
    }
   ],
   "source": [
    "show_scores(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
